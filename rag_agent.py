import faiss
import pickle
from sentence_transformers import SentenceTransformer
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import END, StateGraph
from typing_extensions import TypedDict
from langchain_ollama import OllamaLLM
from transformers import pipeline


class AgentState(TypedDict):
    question: str
    Answer: str
    docs: list[str]
    historical_questions: list[str]
    language: str


class RAGAgent:
    def __init__(self):
        self.model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2', device='cuda')

        # Language detection model
        self.language_detector = pipeline(
            "text-classification",
            model="papluca/xlm-roberta-base-language-detection"
        )

        # Single English index for all queries
        self.index = None
        self.chunks = []
        self.metadata = []

        # Load only English index
        self.load_index("heritage_english.index", "heritage_EN.pkl")

        self.llm = OllamaLLM(model="aya-expanse:8b")
        self.app = self.build_graph()

    def load_index(self, index_file: str, pkl_file: str):
        """Load FAISS index and pickle data (English only)"""
        try:
            self.index = faiss.read_index(index_file)

            with open(pkl_file, 'rb') as f:
                data = pickle.load(f)
                self.chunks = data['chunks']
                self.metadata = data['metadata']

            print(f"âœ… Loaded English index with {len(self.chunks)} chunks")
        except Exception as e:
            print(f"âŒ Error: Could not load English index: {e}")
            self.index = None
            self.chunks = []
            self.metadata = []

    def detect_language(self, text: str) -> str:
        """Detect the language of the input text"""
        try:
            result = self.language_detector(text)[0]
            detected_lang = result['label']
            confidence = result['score']

            print(f"ğŸ” Detected language: {detected_lang} (confidence: {confidence:.2f})")

            # Map detected language to our supported languages
            if detected_lang == 'ar':
                return 'arabic'
            elif detected_lang == 'en':
                return 'english'
            else:
                # For other languages, default to English response
                print(f"âš ï¸  Language '{detected_lang}' detected. Will respond in English.")
                return 'english'

        except Exception as e:
            print(f"âŒ Error detecting language: {e}")
            return 'english'

    def retriever_node(self, state: AgentState):
        print("---NODE: RETRIEVE---")

        # Check if index is loaded
        if self.index is None:
            return {
                'question': state['question'],
                'Answer': 'Sorry, the index is not available.',
                'docs': [],
                'historical_questions': state['historical_questions'],
                'language': state['language']
            }

        # Retrieve from English index (works for both Arabic and English queries
        # because the embedding model is multilingual)
        query_vector = self.model.encode([state['question']])
        distances, indices = self.index.search(query_vector, 10)
        context_chunks = [self.chunks[idx] for idx in indices[0]]

        return {
            'question': state['question'],
            'Answer': state.get('Answer', ''),
            'docs': context_chunks,
            'historical_questions': state['historical_questions'],
            'language': state['language']
        }

    def grader_docs_node(self, state: AgentState):
        print("---NODE: GRADE DOCUMENTS---")
        question = state['question']
        docs = state['docs']
        language = state['language']

        # Use English prompt for grading (internal process)
        prompt_template = """You are a grader. Your job is to check if a
retrieved document is relevant to a user question.
Respond with a *single word*: 'yes' if relevant, 'no' if not.

Document: {document}
Question: {question}

Answer:"""

        prompt = PromptTemplate.from_template(prompt_template)
        grader_chain = prompt | self.llm | StrOutputParser()

        relevant_docs = []
        for doc in docs:
            try:
                result = grader_chain.invoke({"question": question, "document": doc})
                score = result.strip().lower()
                if "yes" in score:
                    print("  -> Grader Decision: Relevant")
                    relevant_docs.append(doc)
                else:
                    print("  -> Grader Decision: NOT Relevant")
            except Exception as e:
                print(f"  -> Grader: Error - {e}")
                continue

        print(f"  -> Found {len(relevant_docs)} relevant documents")

        return {
            'question': question,
            'Answer': state.get('Answer', ''),
            'docs': relevant_docs,
            'historical_questions': state['historical_questions'],
            'language': language
        }

    def generate_node(self, state: AgentState):
        print("---NODE: GENERATE---")
        question = state["question"]
        documents = state["docs"]
        language = state["language"]

        # Language-specific generation prompt - respond in the detected language
        if language == 'arabic':
            prompt_template = """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©.
Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„.
Ø¥Ø°Ø§ ÙƒÙ†Øª Ù„Ø§ ØªØ¹Ø±Ù Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ù‚Ù„ ÙÙ‚Ø· Ø£Ù†Ùƒ Ù„Ø§ ØªØ¹Ø±Ù.
ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.

Ø§Ù„Ø³Ø¤Ø§Ù„: {question}
Ø§Ù„Ø³ÙŠØ§Ù‚: {context}

Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…ÙÙŠØ¯Ø©:"""
        else:
            prompt_template = """You are an assistant for question-answering tasks.
Use the following pieces of retrieved context to answer the question.
If you don't know the answer, just say that you don't know.
The answer should be in English.

Question: {question}
Context: {context}

Helpful Answer:"""

        prompt = PromptTemplate.from_template(prompt_template)
        rag_chain = prompt | self.llm | StrOutputParser()

        generation = rag_chain.invoke({
            "context": "\n\n".join(documents),
            "question": question
        })

        print(f"âœ… Generated answer in {language}")

        return {
            'question': question,
            'Answer': generation,
            'docs': documents,
            'historical_questions': state['historical_questions'],
            'language': language
        }

    def rewriter_node(self, state: AgentState):
        print("---NODE: REWRITE QUERY---")
        question = state["question"]
        historical_questions = state["historical_questions"]
        language = state["language"]

        if question in historical_questions:
            error_msg = "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø¥ÙŠØ¬Ø§Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª ØµÙ„Ø© Ø¨Ø¹Ø¯ Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©." if language == 'arabic' else "Could not find relevant information after multiple attempts."
            return {
                "question": question,
                "Answer": error_msg,
                "docs": [],
                "historical_questions": historical_questions,
                "language": language
            }

        historical_questions.append(question)

        # Use English prompt for rewriting (internal process)
        # But keep the query in its original language for better multilingual retrieval
        prompt_template = """You are a query rewriter. Rewrite the following question to be
a concise and specific search query for a vector database.
Keep the query in the same language as the original question.
Respond ONLY with the rewritten query, nothing else.

Original Question: {question}

Rewritten Query:"""

        prompt = PromptTemplate.from_template(prompt_template)
        rewrite_chain = prompt | self.llm | StrOutputParser()

        new_question = rewrite_chain.invoke({"question": question}).strip()
        print(f"  -> Rewritten: {new_question}")

        return {
            "question": new_question,
            "Answer": "",
            "docs": [],
            "historical_questions": historical_questions,
            "language": language
        }

    def decision_node(self, state: AgentState):
        print("---NODE: DECISION---")

        # If we have relevant docs, generate answer
        if state['docs'] and len(state['docs']) > 0:
            print("  -> Decision: GENERATE (found relevant docs)")
            return "generate"

        # If we've tried too many times, end
        if len(state['historical_questions']) >= 3:
            print("  -> Decision: END (too many attempts)")
            return "end"

        # Otherwise, rewrite query
        print("  -> Decision: REWRITE (no relevant docs)")
        return "rewrite"

    def build_graph(self):
        """Build the LangGraph workflow"""
        graph = StateGraph(AgentState)

        graph.add_node("retriever", self.retriever_node)
        graph.add_node("grader", self.grader_docs_node)
        graph.add_node("generate", self.generate_node)
        graph.add_node("rewriter", self.rewriter_node)

        graph.set_entry_point("retriever")

        graph.add_edge("retriever", "grader")

        graph.add_conditional_edges(
            "grader",
            self.decision_node,
            {
                "generate": "generate",
                "rewrite": "rewriter",
                "end": END
            }
        )

        graph.add_edge("rewriter", "retriever")

        graph.add_edge("generate", END)

        return graph.compile()

    def ask(self, question: str):
        """Ask a question using the RAG agent"""
        # Detect language first
        language = self.detect_language(question)

        result = self.app.invoke({
            "question": question,
            "Answer": "",
            "docs": [],
            "historical_questions": [],
            "language": language
        })

        print("\n" + "=" * 70)
        print("FINAL ANSWER")
        print("=" * 70)
        print(result['Answer'])
        print("=" * 70 + "\n")

        return result['Answer']


# Example usage
if __name__ == "__main__":
    agent = RAGAgent()


    # Test with Arabic question
    print("\nğŸ‡¸ğŸ‡¦ Testing Arabic question:")
    agent.ask("Ù…Ø§ Ø£Ù‡Ù… Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© ØºØ²Ø©ØŸ")